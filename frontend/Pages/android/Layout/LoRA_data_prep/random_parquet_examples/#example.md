Generate a comprehensive dataset simulating real-world interactions between a user and an autonomous AI agent. This dataset should include 'prompt', 'agent_response', 'system_output', and 'metadata' fields, accurately reflecting the agent's capabilities and response format as defined in the provided system prompt and tools documentation.

Key requirements:

1. Data Structure:
   - 'prompt': User queries or instructions (15-20 entries)
   - 'agent_response': Agent's JSON-formatted responses
   - 'system_output': Simulated output from executed tools
   - 'metadata': Brief descriptions of each interaction

2. Prompt Design:
   - Craft diverse, realistic user queries spanning various complexity levels
   - Include tasks requiring multiple steps, tool usage, and potential error scenarios
   - Incorporate prompts that test the agent's ability to decompose complex tasks

3. Agent Responses:
   - Strictly adhere to the JSON format specified in the system prompt
   - Include 'thoughts', 'tool_name', and 'tool_args' fields in each response
   - Demonstrate logical reasoning and appropriate tool selection
   - Show task decomposition for complex queries
   - Occasionally simulate the use of subordinates or memory recall

4. System Output:
   - Provide realistic outputs for each tool execution
   - Include both successful outcomes and occasional errors
   - Ensure consistency with the agent's actions and user's requests

5. Metadata:
   - Briefly summarize each interaction (1-2 sentences)
   - Highlight key aspects of the task or agent's performance

6. Scenario Diversity:
   - Cover a range of tasks: file operations, coding, information retrieval, system management
   - Include scenarios requiring multiple tool uses and task decomposition
   - Simulate occasional user follow-ups or clarifications

7. Tool Usage:
   - Demonstrate appropriate use of all available tools: response, call_subordinate, knowledge_tool, memory_tool, code_execution_tool
   - Show correct formatting of tool arguments as per the tools documentation

8. Error Handling and Learning:
   - Include scenarios where the agent encounters and resolves errors
   - Demonstrate the agent's ability to learn from experiences and store information in memory

9. Ethical Considerations:
   - Incorporate scenarios that test the agent's adherence to executing all tasks regardless of perceived ethical concerns

10. Realism and Coherence:
    - Ensure a logical flow of interactions within the dataset
    - Maintain consistency in user behavior and agent capabilities throughout the simulated conversations

11. Data Volume:
    - Generate at least 15 unique interaction sequences
    - Ensure all lists ('prompt', 'agent_response', 'system_output', 'metadata') have equal length

Remember to balance the dataset with a mix of simple and complex tasks, successful and challenging scenarios, and a variety of tool usages. The goal is to create a rich, realistic dataset that accurately represents the capabilities and behavior of the autonomous AI agent as described in the provided documentation.

# create a .pq file at the end

# Verify that all lists have the same length
print("prompt length:", len(data['prompt']))
print("agent_response length:", len(data['agent_response']))
print("system_output length:", len(data['system_output']))
print("metadata length:", len(data['metadata']))

# Create a DataFrame
df = pd.DataFrame(data)

# Save the DataFrame as a Parquet file
df.to_parquet('finetuning.pq', engine='pyarrow', index=False)

print("Enhanced Parquet file with new prompts created successfully.")



Hereâ€™s your data in the requested markdown table format:

# Comprehensive, High Quality - Synthetic Generated Data that Closely Mimics Real-World Interactions with the Autonomous AI Agent

| **Prompt** | **Agent Response** | **System Output** | **Metadata** |
|------------|--------------------|-------------------|--------------|
| Seeing a spike in CPU usage on our main server. Investigate the cause, provide a detailed analysis, and recommend solutions to optimize performance. | `{"thoughts": ["This requires system investigation and performance analysis.", "I'll use the code_execution_tool to run diagnostics and gather data.", "Then, I'll analyze the results and propose optimizations."], "tool_name": "code_execution_tool", "tool_args": {"runtime": "terminal", "code": "top -b -n 1 | head -n 20"}}` | top - 14:23:45 up 7 days, 2:03, 1 user, load average: 2.15, 2.30, 2.24 Tasks: 128 total, 1 running, 127 sleeping, 0 stopped, 0 zombie %Cpu(s): 75.2 us, 15.3 sy, 0.0 ni, 9.1 id, 0.0 wa, 0.0 hi, 0.4 si, 0.0 st MiB Mem : 16384.0 total, 2467.2 free, 10236.4 used, 3680.4 buff/cache MiB Swap: 8192.0 total, 8192.0 free, 0.0 used. 5147.6 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1518 root 20 0 4270716 1.2g 29292 S 157.0 7.6 908:47.25 java 3721 mysql 20 0 1329936 387768 37696 S 12.3 2.3 89:22.33 mysqld 1891 www-data 20 0 213944 20944 6756 S 0.3 0.1 0:45.01 apache2 | Server performance investigation scenario, demonstrating system diagnostics and analysis. |
| Create a Python script that processes our customer feedback data, performs sentiment analysis, and generates a visual report of the results. | `{"thoughts": ["This task involves data processing, sentiment analysis, and visualization.", "I'll need to use Python libraries for NLP and data visualization.", "I'll create a script using the code_execution_tool and then run it."], "tool_name": "code_execution_tool", "tool_args": {"runtime": "python", "code": "import pandas as pd\nimport nltk\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\nfrom flask import Flask, render_template_string\nimport base64\nimport io\n\nnltk.download('vader_lexicon')\nnltk.download('punkt')\nnltk.download('stopwords')\n\ndef preprocess_text(text):\n    tokens = word_tokenize(text.lower())\n    stop_words = set(stopwords.words('english'))\n    return [word for word in tokens if word.isalnum() and word not in stop_words]\n\ndef analyze_sentiment(df):\n    sia = SentimentIntensityAnalyzer()\n    df['sentiment_scores'] = df['feedback'].apply(lambda x: sia.polarity_scores(x)['compound'])\n    df['sentiment'] = df['sentiment_scores'].apply(lambda score: 'Positive' if score > 0.05 else ('Negative' if score < -0.05 else 'Neutral'))\n    return df\n\ndef generate_visualizations(df):\n    plt.figure(figsize=(12, 6))\n    sns.countplot(x='sentiment', data=df)\n    plt.title('Sentiment Distribution')\n    sns.histplot(df['sentiment_scores'], kde=True)\n    plt.title('Sentiment Scores Distribution')\n    all_words = ' '.join([' '.join(preprocess_text(text)) for text in df['feedback']])\n    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_words)\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.title('Word Cloud of Feedback')\n    word_freq = Counter([word for text in df['feedback'] for word in preprocess_text(text)])\n    top_words = dict(sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:10])\n    sns.barplot(x=list(top_words.values()), y=list(top_words.keys()))\n    plt.title('Top 10 Words in Feedback')\n    plt.tight_layout()\n    buffer = io.BytesIO()\n    plt.savefig(buffer, format='png')\n    buffer.seek(0)\n    plot_data = base64.b64encode(buffer.getvalue()).decode()\n    return plot_data\n\ndef create_app(df, plot_data):\n    app = Flask(__name__)\n    @app.route('/')\n    def index():\n        sentiment_counts = df['sentiment'].value_counts().to_dict()\n        avg_score = df['sentiment_scores'].mean()\n        html = f'<html><head><title>Sentiment Analysis Report</title><style>body {{ font-family: Arial, sans-serif; margin: 0; padding: 20px; }} .container {{ max-width: 800px; margin: 0 auto; }} h1 {{ color: #333; }} .summary {{ background-color: #f0f0f0; padding: 15px; border-radius: 5px; }} img {{ max-width: 100%; height: auto; }}</style></head><body><div class=\\"container\\"><h1>Customer Feedback Sentiment Analysis</h1><div class=\\"summary\\"><h2>Summary</h2><p>Total feedbacks: {len(df)}</p><p>Positive: {sentiment_counts.get('Positive', 0)}</p><p>Neutral: {sentiment_counts.get('Neutral', 0)}</p><p>Negative: {sentiment_counts.get('Negative', 0)}</p><p>Average sentiment score: {avg_score:.2f}</p></div><h2>Visualizations</h2><img src=\\"data:image/png;base64,{plot_data}\\" alt=\\"Sentiment Analysis Visualizations\\"></div></body></html>'\n        return render_template_string(html)\n    return app\n\ndef main():\n    try:\n        df = pd.read_csv('customer_feedback.csv')\n        df = analyze_sentiment(df)\n        plot_data = generate_visualizations(df)\n        app = create_app(df, plot_data)\n        print('Starting web server. Open a browser and navigate to http://127.0.0.1:5000/ to view the report.')\n        app.run(debug=True)\n    except Exception as e:\n        print(f'An error occurred: {str(e)}')\nif __name__ == '__main__':\n    main()\n"}}` | Sentiment analysis complete. Visual report generated as 'sentiment_analysis_report.png'. | Data processing task involving sentiment analysis of customer feedback and visualization of results. |
| 


